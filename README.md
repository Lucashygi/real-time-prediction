# **Como realizar a inferÃªncia do seu modelo de detecÃ§Ã£o de objetos em Tempo Real** â³ğŸ¤–ğŸ‘©â€ğŸ’»ğŸ’»

Depois que vocÃª treinou e validou o seu modelo no *Google Colab*, agora iremos validar o seu modelo realizando inferÃªncia em tempo real ou em video.

Para isso precisamos preparar o ambiente para podermos executar com sucesso o 
nosso modelo, portanto iremos divir esse tutorial nas seguintes etapas:

1. InstalaÃ§Ã£o das Bibliotecas;
2. Clonagem do RepositÃ³rio Tensorflow API;
3. InstalaÃ§Ã£o dos pacotes do RepositÃ³rio clonado; 
4. PreparaÃ§Ã£o dos arquivos Necessarios;
5. Executar o script e correr para o abraÃ§o;

Nesse primeiro momento, esse tutorial se refere a Arquitetura EfficientDet;

![](https://img.shields.io/badge/Visual_Studio-5C2D91?logo=visual%20studio&logoColor=white)

## Executando as Etapas:

Antes de mais nada, abra o terminal e execute esses dois comandos `PIP`:

```
$ pip uninstall object-detection-0.1
$ pip uninstall object-detection
```

Nessa primeira etapa, iremos instalar os pacotes necessÃ¡rios atravÃ©s de um script
apenas, para isso, abra o terminal de comando na pasta raiz do projeto e 
execute o seguinte:
```
$	python script/setup.py
```
Se tudo ocorrer bem, vocÃª devera estar com `Instalador do Visual Studio` aberto,
como a representaÃ§Ã£o da imagem.

<img src="images\visual-studio-installer.png" alt="model_saved" style="height: 360px; width:780px;"/>

â–¶ Com o instalador aberto, siga as instruÃ§Ãµes das imagens abaixo clickando nas Ã¡reas
demarcadas:

## **Passo 1**
â–¶ Click em modificar para abrir os pacotes disponiveis

<img src="images\visual-studio-installer-modificar.png" alt="model_saved" style="height: 360px; width:780px;"/>

## **Passo 2**
â–¶ Em seguida, seleciona o pacote e click em 'modificar' para comeÃ§ar a instalaÃ§Ã£o

<img src="images\visual-studio-installer-instalacao.png" alt="model_saved" style="height: 360px; width:780px;"/>

## **Passo 3**
â–¶ ApÃ³s o passo 2, a instalaÃ§Ã£o deve comeÃ§ar

<img src="images\visual-studio-installer-instalacao-processo.png" alt="model_saved" style="height: 360px; width:780px;"/>


## ğŸ¤– **EfficientDet**  
Nessa primeira etapa, iremos preparar o ambiente para a arquitetuta *EfficientDet*.

ğŸ¤– 1. Primeira Etapa: Abra o terminal na raiz do projeto execute o seguinte 
comando para clonar o repositorio que contem os scrips necessÃ¡rios e instalar
as dependÃªncias e pacotes.
```
$	python script/setup.py
```

ğŸ¤– 2. Segunda Etapa: Instalar o *protobuf releases* em seu sistema operacional,  
caso vocÃª nÃ£o tenha. Para isso, deixarei um tutorial que vocÃª possar estar seguindo  
para efetuar a instalaÃ§Ã£o;

[![Tutorial Youtube](https://img.shields.io/badge/youtube-red.svg?logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=ES_GI-lmhEU)

ğŸ¤– 3. Terceira Etapa: Instalar dependÃªcias via *PROTOBUF*, com o protobuf instalado
abra o terminal na raiz do projeto e navegue ate a pasta `/research`, para
isso, execute na raiz do projeto:
```
$ cd models/research
```
em seguida, execute:
```
$ protoc object_detection/protos/*.proto --python_out=.
```
por fim, efetue as ultimas instalaÃ§Ãµes, executando:
```
$ python object_detection/packages/tf2/setup.py install
```
Se tudo ocorrer bem e com sucesso, vocÃª agora esta pronto para executar o script
principal.

ğŸ”¥ Por fim, execute esse script no terminal no mesmo diretÃ³rio que os anteriores:
```
$ SET PYTHONPATH=%cd%:%cd%\slim
```

### ğŸ—„ **Organizando os arquivos.**

Agora que vocÃª ja preparou o Ambiente e esta tudo pronto, vamos organizar os 
arquivos necessarios, que sÃ£o eles:
* ğŸ“ *pipeline_file.config* ou *pipeline.config*
* ğŸ“ *label_map.pbtxt*
* ğŸ“ *(model ckpt)*
* ğŸ“ *(weight ckpt)*

Esses 4 sÃ£o os principais arquivos para a nossa inferÃªncia. Quando vocÃª terminou 
de treinar o seu modelo customizado no Beegeye, foi gerado todos essesa arquivos 
listados anteriormente. 

- ğŸ“**pipeline_file.config ou pipeline.config** - Ã‰ o arquivo que usamos para  
efetuar o treinamento, que contÃªm as nossas configuraÃ§Ãµes personalizadas, esse  
arquivo Ã© salvo dentro do seu *GOOGLE DRIVE*   dentro da pasta *fine-tuned_model*, 
verifique obter corretamente esse arquivo.

	<img src="images\drive-fine_tuned_model.png" alt="fine-tuned" style="height: 360px; width:780px;"/>

- ğŸ“**label_map.pbtxt** - Ã‰ o arquivo que usamos para rotular nossas classes, que 
a imagem abaixo esta representando. Esse arquivo esta dentro da pasta *data.zip*  
que o *Beegeye* gera e faz upload da mesma dentro do Google Drive.
  
	<img src="images\label-map.png" alt="label map" style="height: 360px; width:780px;"/>


- ğŸ“**model ckpt e weight ckpt** - Aqui sÃ£o os arquivos gerados pelo treinamento,  
ou seja, os checkpoints. Esses checkpoints vocÃª pode estar obtendo dentro da pasta  
*model_saved* no ambiente do *Colab*. Onde vai  estar localizado todos os 
chekpoints gerados. Cada um dos ckpts possui uma numeraÃ§Ã£o no mesmo nome, por 
exemplo: `ckpt-0`, `ckpt-1`, etc. Preste atenÃ§Ã£o nos arquivos, cada numeraÃ§Ã£o 
possue dois arquivos, um `.data-00000-of-00001` e `.index` e sÃ£o esses arquivos 
que vocÃª tem que ter.

	<img src="images\model_saved.png" alt="model_saved" style="height: 360px; width:780px;"/>

ou vocÃª pode estar encontrando os Ãºltimos checkpoints gerados na pasta drive:

	<img src="images\checkpoint.png" alt="model_saved" style="height: 360px; width:780px;"/>

Bem, possuindo todos os arquivos listado acima, agora vocÃª deve armazerna-los  
dentro das seguintes pastas:

âœ” pipeline_file.config dentro da pasta models/efficientdet

âœ” label_map.pbtxt dentro da pasta models/efficientdet

âœ” ckpts dentro da pasta models/efficientdet

Feito isso, abra o script `real-time-prediction.py` e verifique nas seguinte  
linhas 46 ao 51 as seguintes variaveis.

~~~python
46 pipeline_config  = './models/efficientdet/pipeline_file.config'
47 label_map_path   = './models/efficientdet/label_map.pbtxt'
# Altere o numero do ckpt para o numero que corresponde ao seu chekpoint
48 model_dir 	    = './models/efficientdet/ckpt-2' 
49 checkpoint	    = './models/efficientdet/ckpt-2'

50 inputVideo  	    = './videos/input.mp4' # or 0 to started Webcan
51 outputVideo      = './output.mp4'
~~~

Verifique as variaveis e o caminho que corresponde a cada um dos arquivos. 

### ğŸš¨ **AtenÃ§Ã£o - As seguite variaveis** ğŸš¨ 

âœ” inputVideo representa a variavel que carregarÃ¡ o video, webcam ou qualquer  
outra entrada de video, altere essa variavel.

âœ” outputVideo - Gravara a prediÃ§Ã£o em  formato de video.


Portanto, com essas etapas vocÃª deve conseguir com sucesso realizar  inferencia  
do seu modelo treinado atravÃ©s do BeegEye em Tempo real para a arquitetura **EfficientDet**


### ğŸ‘€ **OBSERVAÃ‡ÃƒO** ğŸ‘€

VocÃª pode tentar usar esse mesmo script para as outras arquiteturas que o BeegEye  
disponibiliza, sÃ³ lembre de usar os ckpts principais `ckpt-index` e `ckpt.data`.


## ğŸ“± **Qualquer DÃºvida ou Erros, entre em Contato via:**
---
[![Tutorial Youtube](https://img.shields.io/badge/WhatsApp-gree.svg?logo=WhatsApp&logoColor=white)](https://api.whatsapp.com/send?phone=5547991081602)  

[![Tutorial Youtube](https://img.shields.io/badge/Email-blue.svg?logo=microsoft-outlook&logoColor=white)](https://api.whatsapp.com/send?phone=5547991081602)
